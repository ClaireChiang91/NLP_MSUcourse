{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_HW1_Part4_N-Gram language Models_v5",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN81m8aJyJtBfGHqzfN5UbT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ClaireChiang91/NLP_MSUcourse/blob/main/NLP_HW1_Part4_N_Gram_language_Models_v5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psRUgYV49Z3T"
      },
      "source": [
        "This program is going to do with the assignment for the NLP course at MSU. \n",
        "https://github.com/deskool/nlp-class\n",
        "Homework1 Learning Excerse 4:\n",
        "https://github.com/deskool/nlp-class/blob/master/homework/HW1/assignment.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP8g31L6_7mm"
      },
      "source": [
        "**N-grams**\n",
        "An n-gram is a contiguous sequence of n items from a given sample of text or speech. Let's begin this section by defining a function that generates n-grams from our text data using the nltk library and using it to extract n-grams for n ranging from 1-5.\n",
        "**The challenge**\n",
        "Now that you have built your first language model, let's turn our attention back to the philosophers. For this final learning exercise, you will be building a tri-gram Nietzsche language model, and a tri-gram Russel Language Model using the 5 books from each of the philosophers you collected from Project Gutenburg earlier.\n",
        "\n",
        "Generate a conversation between your philosophers models by seeding one of the models with a tri-gram and allow it to run until it generates a terminating character (a '.', '?' or '!'). Then, have the other model generate a response by providing the ending tri-gram of the the first model as the seed tri-gram for the other model. Iterate like this for 15 sentences and print the text.\n",
        "\n",
        "Note: You probably learned from the earlier components of this assignment that Nietzsche and Russel have slightly different writing styles (yes, that was an understatement). For this reason, there are likely to be instances where the ending tri-gram from your Nietzsche model does not show up in the Russel language model and vice-versa. Use Laplace smoothing to handle this problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLXgF2SyoN1I",
        "outputId": "789cda6a-d1ad-4a90-bf0a-2e86e63adb2b"
      },
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "#to solve the error msg: Resource punkt not found. \n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l7v0puNHF_L"
      },
      "source": [
        "# Nietzsche\n",
        "website = 'http://www.gutenberg.org/cache/epub/4363/pg4363.txt'\n",
        "nietz    = requests.get(website).text[:200]\n",
        "\n",
        "# Russel\n",
        "website = 'http://www.gutenberg.org/cache/epub/5827/pg5827.txt'\n",
        "russel = requests.get(website).text[:200]\n",
        "########################################################################\n",
        "#to apply the request of iterating 15 sentences\n",
        "max_setence=15 \n",
        "#k smoothing, which could be 0.05, 0.5 or 1; 1 is to apply the reuqest of using Laplace\n",
        "k=1\n",
        "#stands for n-grams\n",
        "n=3"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vFxoS2rCbFw"
      },
      "source": [
        "#define an ngram extractor\n",
        "def extract_word_ngrams(data, num):\n",
        "    n_grams = ngrams(nltk.word_tokenize(data), num)\n",
        "    return [ ' '.join(grams) for grams in n_grams]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjP_axUMscax"
      },
      "source": [
        "def language_model(philosopher,size,k):\n",
        "  grams=extract_word_ngrams(philosopher, size)\n",
        "  vocabulary = list(set(grams))\n",
        "  counts = {}\n",
        "  for given_word in vocabulary:\n",
        "    counts[given_word] = {}\n",
        "    for next_word in vocabulary:\n",
        "        counts[given_word][next_word] = 0 \n",
        "\n",
        "  for i in range(len(grams)-1):\n",
        "    counts[grams[i]][grams[i+1]] += 1\n",
        "\n",
        "  # initialize the probabilites JSON object\n",
        "  probs = {}\n",
        "  for given_word in vocabulary:\n",
        "    probs[given_word] = {}\n",
        "    for next_word in vocabulary:\n",
        "      probs[given_word][next_word] = 0\n",
        "\n",
        "  # convert the counts to probabilites\n",
        "  for key, value in counts.items():\n",
        "    denominator = 0\n",
        "    for key2, value2 in counts[key].items():\n",
        "      denominator += value2\n",
        "    for key2, value2 in counts[key].items():\n",
        "      #Add-k smoothing\n",
        "      probs[key][key2] = (value2+k) / (denominator+k*len(vocabulary))\n",
        "  return probs"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6vPgZnkI-hu"
      },
      "source": [
        "def sample_next_gram_from_language_model(probs, given_token):\n",
        "    distribution            = list(probs[given_token].values())\n",
        "    sample_from_multinomial = np.random.multinomial(1,distribution)\n",
        "    sample_index            = np.where(sample_from_multinomial==1)[0][0]\n",
        "    word_keys               = list(probs[given_token].keys())\n",
        "    next_word               = word_keys[sample_index]\n",
        "    return(next_word)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoDfov_lJ0ru"
      },
      "source": [
        "def create_new_sentence(_probs_,seed_token):\n",
        "    tokens = [seed_token]\n",
        "    while any([' '.join(tokens).split(' ')[-1] not in ['.', '?','!'] ]):\n",
        "      _next_word_=sample_next_gram_from_language_model(_probs_,tokens[-1])\n",
        "      if all([_next_word_.split(' ')[i] not in ['.', '?','!'] for i in range(len(_next_word_.split(' ')))]):\n",
        "        tokens.append(_next_word_)\n",
        "      else:\n",
        "        i_index=0\n",
        "        while i_index < len(_next_word_.split(' ')):\n",
        "          _nextword_=_next_word_.split(' ')[i_index]\n",
        "          i_index+=1\n",
        "          if _nextword_ not in ['.', '?','!']:\n",
        "            tokens.append(_nextword_)\n",
        "          else:  \n",
        "            tokens.append(_nextword_)\n",
        "            break\n",
        "    return tokens"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "tBz3Ca7GfQ47",
        "outputId": "936fd655-29dd-4498-bab8-5b9b31fa3fe9"
      },
      "source": [
        "nietz_probs=language_model(nietz, n,k)\n",
        "seed_token_nietz= 'Good and Evil'\n",
        "' '.join(create_new_sentence(nietz_probs, seed_token_nietz))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Good and Evil , by Friedrich Evil , by of anyone anywhere Nietzsche This eBook the use of You may copy use of anyone the use of and with almost Beyond Good and restrictions whatsoever .'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "-Icbf6oegpBh",
        "outputId": "77e37a11-cf63-47f2-c569-c114ee7df574"
      },
      "source": [
        "russel_probs=language_model(russel, n,k)\n",
        "seed_token_russel= 'no cost and'\n",
        "\n",
        "' '.join(create_new_sentence(russel_probs, seed_token_russel))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"no cost and no restrictions whatsoever use of anyone anyone anywhere at Problems of Philosophy of Philosophy , anyone anywhere at Philosophy , by is for the anyone anywhere at anywhere at no of Philosophy , the use of of Philosophy , Gutenberg 's The no restrictions whatsoever by Bertrand Russell The Problems of You may copy , by Bertrand anyone anywhere at Problems of Philosophy it , give the use of no cost and Russell This eBook is for the use of anyone \\ufeffProject Gutenberg 's Problems of Philosophy Bertrand Russell This Bertrand Russell This Philosophy , by 's The Problems may copy it Gutenberg 's The is for the it , give Gutenberg 's The the use of and with almost whatsoever .\""
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MExA0voRgfcC"
      },
      "source": [
        "def conversation(seed_p,max_setence):\n",
        "  #opening\n",
        "  initial_set=0\n",
        "  if seed_p=='nietz':\n",
        "    initial_seed='Good and Evil'\n",
        "    initial_talk=' '.join(create_new_sentence(nietz_probs, initial_seed))\n",
        "    print(\"counts:\",initial_set)\n",
        "    print(seed_p,\"initially say:\",initial_talk)\n",
        "    print(\"=========\")  \n",
        "    initial_set+=1\n",
        "    seed_p='russel'\n",
        "  else:\n",
        "    initial_seed='no cost and'\n",
        "    initial_talk=' '.join(create_new_sentence(russel_probs, initial_seed))\n",
        "    print(\"counts:\",initial_set)\n",
        "    print(seed_p,\"initially say:\",initial_talk)\n",
        "    print(\"=========\")\n",
        "    initial_set+=1\n",
        "    seed_p='nietz'\n",
        "\n",
        " #response\n",
        "  while initial_set<=max_setence:\n",
        "    if seed_p=='nietz':\n",
        "      next_seed=' '.join(initial_talk.split(\" \")[-3:])\n",
        "      if next_seed in nietz_probs.keys():\n",
        "        response=' '.join(create_new_sentence(nietz_probs, next_seed))\n",
        "        print(\"counts:\",initial_set)\n",
        "        print(seed_p,\"responds:\",response)\n",
        "        print(\"=========\")\n",
        "        seed_p='russel'\n",
        "        initial_set+=1\n",
        "      else:\n",
        "        for i in range(0,len(initial_talk.split(\" \"))-3):\n",
        "          next_seed=' '.join(initial_talk.split(\" \")[(-4-i):(-1-i)])\n",
        "          if next_seed in nietz_probs.keys():\n",
        "            response=' '.join(create_new_sentence(nietz_probs, next_seed))\n",
        "            print(\"counts:\",initial_set)\n",
        "            print(seed_p,\"responds:\",response)\n",
        "            print(\"=========\")\n",
        "            seed_p='russel'\n",
        "            initial_set+=1\n",
        "          else:\n",
        "            print(\"counts:\",initial_set)\n",
        "            print(seed_p,\"responds: no respone\")\n",
        "            print(\"===end======\")\n",
        "            initial_set+=1\n",
        "            seed_p='russel'\n",
        "    else:\n",
        "      next_seed=' '.join(initial_talk.split(\" \")[-3:])\n",
        "      if next_seed in russel_probs.keys():\n",
        "        response=' '.join(create_new_sentence(russel_probs, next_seed))\n",
        "        print(\"counts:\",initial_set)\n",
        "        print(seed_p,\"responds:\",response)\n",
        "        print(\"=========\")\n",
        "        seed_p='nietz'\n",
        "        initial_set+=1\n",
        "      else:\n",
        "        for i in range(0,len(initial_talk.split(\" \"))-3):\n",
        "          next_seed=' '.join(initial_talk.split(\" \")[(-4-i):(-1-i)])\n",
        "          if next_seed in russel_probs.keys():\n",
        "            response=' '.join(create_new_sentence(nietz_probs, next_seed))\n",
        "            print(seed_p,\"responds:\",response)\n",
        "            print(\"=========\")\n",
        "            seed_p='nietz'\n",
        "            initial_set+=1\n",
        "          else:\n",
        "            print(\"counts:\",initial_set)\n",
        "            print(seed_p,\"responds: no respone\")\n",
        "            print(\"===end======\") \n",
        "            initial_set+=1\n",
        "            seed_p='nietz'"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhUqrL7Ijzju",
        "outputId": "cedcf06e-038b-4369-9e8a-cb5fcf4f8db5"
      },
      "source": [
        "conversation('nietz',max_setence )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counts: 0\n",
            "nietz initially say: Good and Evil and with almost , by Friedrich no cost and eBook is for EBook of Beyond almost no restrictions may copy it , by Friedrich it , g of anyone anywhere Beyond Good and Good and Evil by Friedrich Nietzsche is for the anywhere at no Gutenberg EBook of EBook of Beyond EBook of Beyond Gutenberg EBook of Beyond Good and of anyone anywhere the use of Friedrich Nietzsche This and Evil , Evil , by at no cost This eBook is by Friedrich Nietzsche eBook is for use of anyone , by Friedrich restrictions whatsoever .\n",
            "=========\n",
            "counts: 1\n",
            "russel responds: restrictions whatsoever .\n",
            "=========\n",
            "counts: 2\n",
            "nietz responds: restrictions whatsoever .\n",
            "=========\n",
            "counts: 3\n",
            "russel responds: restrictions whatsoever .\n",
            "=========\n",
            "counts: 4\n",
            "nietz responds: restrictions whatsoever .\n",
            "=========\n",
            "counts: 5\n",
            "russel responds: restrictions whatsoever .\n",
            "=========\n",
            "counts: 6\n",
            "nietz responds: restrictions whatsoever .\n",
            "=========\n",
            "counts: 7\n",
            "russel responds: restrictions whatsoever .\n",
            "=========\n",
            "counts: 8\n",
            "nietz responds: restrictions whatsoever .\n",
            "=========\n",
            "counts: 9\n",
            "russel responds: restrictions whatsoever .\n",
            "=========\n",
            "counts: 10\n",
            "nietz responds: restrictions whatsoever .\n",
            "=========\n",
            "counts: 11\n",
            "russel responds: restrictions whatsoever .\n",
            "=========\n",
            "counts: 12\n",
            "nietz responds: restrictions whatsoever .\n",
            "=========\n",
            "counts: 13\n",
            "russel responds: restrictions whatsoever .\n",
            "=========\n",
            "counts: 14\n",
            "nietz responds: restrictions whatsoever .\n",
            "=========\n",
            "counts: 15\n",
            "russel responds: restrictions whatsoever .\n",
            "=========\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H6zrxSosDw7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}